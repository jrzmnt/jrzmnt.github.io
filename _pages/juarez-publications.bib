@inproceedings{monteiro2018bomberman,
  title={Using Scene Context to Improve Action Recognition},
  author={Monteiro, Juarez and Granada, Roger and Meneguzzi, Felipe R and Barros, Rodrigo C},
  booktitle={Iberoamerican Congress on Pattern Recognition (CIARP)},
  series    = {CIARP'18},
  location  = {Madrid, Spain},
  year      = {2018},
  publisher = {Springer},
  abstract = {Recently action recognition has been used for a variety of applications such as surveillance, smart homes, and in-home elder monitoring. Such applications usually focus on recognizing human actions without taking into account the different scenarios where the action occurs. In this paper, we propose a two-stream architecture that considers not only the movements to identify the action, but also the context scene where the action is performed. Experiments show that the scene context may improve the recognition of certain actions. Our proposed architecture is tested against baselines and the standard two-stream network.}
}


@inproceedings{monteiro2018bomberman,
  title={Beating Bomberman with Artificial Intelligence},
  author={Monteiro, Juarez and Granada, Roger and Pinto, Rafael C and Barros, Rodrigo C},
  booktitle={XV Encontro Nacional de Inteligência Artificial e Computacional},
  series    = {ENIAC'18},
  location  = {São Paulo, Brazil},
  year      = {2018},
  organization = {SBC},
  abstract = {Artificial Intelligence (AI) seeks to bring intelligent behavior for machines by using specific techniques. These techniques can be employed in order to solve tasks, such as planning paths or controlling intelligent agents. Some tasks that use AI techniques are not trivially testable, since it can handle a high number of variables depending on their complexity. As digital games can provide a wide range of variables, they become an efficient and economical means for testing artificial intelligence techniques. In this paper, we propose a combination of a behavior tree and a Pathfinding algorithm to solve a maze-based problem using the digital game Bomberman of the Nintendo Entertainment System (NES) platform. We perform an analysis of the AI techniques in order to verify the feasibility of future experiments in similar complex environments. Our experiments show that our intelligent agent can be successfully implemented using the proposed approach.}
}


@inproceedings{MonteiroEtAl2018,
  author    = {Monteiro, Juarez and Granada, Roger and Aires, Jo{\~a}o P and Barros, Rodrigo C},
  title     = {Evaluating the Feasibility of Deep Learning for Action Recognition in Small Datasets},
  booktitle = {Proceedings of the 2018 International Joint Conference on Neural Networks},
  series    = {IJCNN'18},
  location  = {Rio de Janeiro, Brazil},
  year      = {2018},
  publisher = {IEEE}
}

@inproceedings{AiresEtAl2018,
  author    = {Aires, Jo{\~a}o P and Granada, Roger and Monteiro, Juarez and Meneguzzi, Felipe},
  title     = {Norm Conflict Identification using Vector Space Offsets},
  booktitle = {Proceedings of the 2018 International Joint Conference on Neural Networks},
  series    = {IJCNN'18},
  location  = {Rio de Janeiro, Brazil},
  year      = {2018},
  publisher = {IEEE}
}

@inproceedings{AiresEtAl2017kdmile,
  author    = {Aires, Jo\~{a}o Paulo and Monteiro, Juarez and Granada, Roger and Meneguzzi, Felipe and Barros, Rodrigo C},
  title     = {Improving Activity Recognition using Temporal Regions},
  booktitle = {Proceedings of the 5th Symposium on Knowledge Discovery, Mining and Learning},
  series    = {KDMiLe 2017},
  location  = {Uberl\^{a}ndia, MG, Brazil},
  pages     = {89--96},
  issn      = {2318-1060},
  month     = {October},
  year      = {2017},
  organization = {SBC},
  abstract = {Recognizing activities in videos is an important task in computer vision area. Automatizing such task can improve the way we monitor activities since it is not necessary to have a human to watch every video. However, the classification of activities in a video is a challenging task since we need to extract temporal features that represent each activity. In this work, we propose an approach to obtain temporal features from videos by dividing the sequence of frames of a video into regions. Frames from these regions are merged in order to identify the temporal aspect that classify activities in a video. Our approach yields better results when compared to a frame-by-frame classification.}
}

@inproceedings{silva2017object,
  title={Using Scene Context to Improve Object Recognition},
  author={Silva, Leandro P. da and Granada, Roger and Monteiro, Juarez and Ruiz, Duncan D.},
  booktitle={Proceedings of the 5th Symposium on Knowledge Discovery, Mining and Learning (KDMILE)},
  year={2017},
  organization={SBC},
  abstract =  {Computer vision is the science that aims to give computers the capability of seeing the world around them. Among its tasks, object recognition intends to classify objects and to identify where each object is in a given image. As objects tend to occur in particular environments, their contextual association can be useful to improve the object recognition task. To address the contextual awareness on object recognition task, our approach aims to use the context of the scenes in order to achieve higher quality in object recognition, by fusing context information with object detection features. Hence, we propose a novel architecture composed of two convolutional neural networks based on two well-known pre-trained nets: Places365 and Faster R-CNN. Our two-streams architecture uses the concatenation of object features with scene context features in a late fusion approach. We perform experiments using PASCAL VOC 2007 and MS COCO public datasets, analyzing its performance in different values of intersection over union. Results show that our approach is able to raise in-context object scores, and reduces out-of-context objects scores.},
}

@inproceedings{monteiro2017deep,
  title={Deep neural networks for kitchen activity recognition},
  author={Monteiro, Juarez and Granada, Roger and Barros, Rodrigo C and Meneguzzi, Felipe},
  booktitle={Neural Networks (IJCNN), 2017 International Joint Conference on},
  pages={2048--2055},
  year={2017},
  organization={IEEE},
  abstract =  {With the growth of video content produced by mobile cameras and surveillance systems, an increasing amount of data is becoming available and can be used for a variety of applications such as video surveillance, smart homes, smart cities, and in-home elder monitoring. Such applications focus in recognizing human activities in order to perform different tasks allowing the opportunity to support people in their different scenarios. In this paper we propose a deep neural architecture for kitchen human action recognition. This architecture contains an ensemble of convolutional neural networks connected through different fusion methods to predict the label of each action. Experiments show that our architecture achieves the novel state-of-the-art for identifying cooking actions in a well-known kitchen dataset.},
  url = {files/deep_neural_networks_for_kitchen_activity_recognition.pdf}
}

@inproceedings{monteiro2017virtual,
  title={Virtual guide dog: An application to support visually-impaired people through deep convolutional neural networks},
  author={Monteiro, Juarez and Aires, Joao Paulo and Granada, Roger and Barros, Rodrigo C and Meneguzzi, Felipe},
  booktitle={Neural Networks (IJCNN), 2017 International Joint Conference on},
  pages={2267--2274},
  year={2017},
  organization={IEEE},
  abstract = {Activity recognition applications is growing in importance due to two key factors: first there is increased need for more human assistance and surveillance; and second, increased availability of datasets and improved image recognition algorithms have allowed effective recognition of more sophisticated activities. In this paper we develop an activity recognition approach to support visually impaired people that leverages these advances. Specifically, our approach uses a dataset of videos taken from the point of view of a guide-dog to train a convolutional neural-network to recognize the activities taking place around the camera and provide feedback to a visually impaired human user. Our experiments show that our trained models surpass the current state-of-the-art for identifying activities in the doc-centric activity dataset.},
  url = {files/virtual_guide_dog.pdf}
}

@inproceedings{granada2017hybrid,
  title={Hybrid activity and plan recognition for video streams},
  author={Granada, Roger and Pereira, Ramon Fraga and Monteiro, Juarez and Ruiz, Duncan D and Barros, Rodrigo Coelho and Meneguzzi, Felipe},
  booktitle={Proceedings of the AAAI Workshop on Plan, Activity, and Intent Recognition (PAIR)},
  year={2017},
  abstract = {Computer-based human activity recognition of daily living has recently attracted much interest due to its applicability to ambient assisted living. Such applications require the automatic recognition of high-level activities composed of multiple actions performed by human beings in an environment. In this work, we address the problem of activity recognition in an indoor environment, focusing on a kitchen scenario. Unlike existing approaches that identify single actions from video sequences, we also identify the goal towards which the subject of the video is pursuing. Our hybrid approach combines a deep learning architecture to analyze raw video data and identify individual actions which are then processed by a goal recognition algorithm that uses a plan library describing possible overarching activities to identify the ultimate goal of the subject in the video. Experiments show that our approach achieves the state-of-the-art for identifying cooking activities in a kitchen scenario.},
  url = {files/pair-hybrid-recognizer-2017.pdf}
}

@inproceedings{maidana2017chinese,
  title={Deep Neural Networks for Handwritten Chinese Character Recognition},
  author={Maidana, Renan and Monteiro, Juarez and Granada, Roger and Amory, Alexandre and Barros, Rodrigo Coelho},
  booktitle={Proceedings of the Brazilian Conference on Intelligent Systems (BRACIS)},
  year={2017}
}

@inproceedings{simoes2016datasex,
  title={DataSex: um dataset para indução de modelos de classificação para conteúdo adulto},
  author={Simoes, Gabriel and Wehrmann, Jonatas and Paula, Thomas da Silva and Monteiro, Juarez and Barros, Rodrigo Coelho},
  booktitle={Proceedings of the 3rd Symposium on Knowledge Discovery, Mining and Learning (KDMILE)},
  year={2016},
  pages={202--209},
  abstract = {O consumo indiscriminado de conteúdo adulto na Internet gera problemas comportamentais que, em alguns casos, pode desencadear patologias. A facilidade de acesso e o anonimato criam um ambiente propício ao consumo deste tipo de conteúdo. Neste cenário, classificadores podem ser treinados para identificar automaticamente conteúdo adulto, abrindo espaço para o monitoramento e o controle de acesso. Este trabalho descreve a criação do DataSex, um dataset composto por 286.920 imagens para indução de modelos de Aprendizagem de Máquina que possam efetivamente contribuir para este controle. Experimentos apontam que Redes Neurais Convolucionais podem atingir aproximadamente 95% de acurácia de teste quando treinadas com este conjunto de dados},
  url = {http://cin.ufpe.br/~rv2/kdmile2016/anais-kdmile-2016.pdf}
}

@inproceedings{Monteiro2017,
  author =    {Juarez Monteiro and JoÃ£o Paulo Aires and Roger Granada and Felipe Meneguzzi and Rodrigo Barros},
  title =     {Temporal Regions for Activity Recognition},
  booktitle = {Proceedings of the 26th International Conference on Artificial Neural Networks},
  year =      {2017}
}

@inproceedings{granada2017deep,
  title={A Deep Neural Architecture for Kitchen Activity Recognition},
  author={Granada, Roger and Monteiro, Juarez and Barros, Rodrigo Coelho and Meneguzzi, Felipe},
  year={2017},
  booktitle={The Florida Artificial Intelligence Research Society Conference (FLAIRS)},
  abstract = {Computer-based human activity recognition of daily living has recently attracted much interest due to its applicability to ambient assisted living. Such applications require the automatic recognition of high-level activities composed of multiple actions performed by human beings in a given environment. We propose a deep neural architecture for kitchen activity recognition, which uses an ensemble of machine learning models and hand-crafted features to extract more information of the data. Experiments show that our approach achieves the state-of-the-art for identifying cooking actions in a wellknown kitchen dataset.},
  url = {files/deep_neural_networks_for_kitchen_flairs.pdf}
}

@conference{monteiro2015analise,
  title={Análise da Aplicabilidade de Técnicas de Inteligência Artificial em um Jogo Digital},
  author={Monteiro, Juarez and Pinto, Rafael Coimbra},
  year={2015},
  booktitle={V Salão de Iniciação Científica e Tecnológica do Intituto Federal do Rio Grande do Sul - Câmpus Canoas (IFRS)}
}
